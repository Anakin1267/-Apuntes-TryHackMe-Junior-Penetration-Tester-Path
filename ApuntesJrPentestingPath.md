# <span style="color:green;">**JUNIOR PENTESTING PATH - THM**</span>  

> Esto van a ser unos apuntes de repaso sobre la ruta de aprendizaje de TryHackMe "Jr Penetraition Tester", aquí trataremos sobre todo aquellos módulos interesantes pero que quizás estan poco explicados y detallados en el curso, así además, aproechamos para recordar nombres de herramientas, comandos, siglas etc. Igual que aquí muchos módulos están explicados a fondo, muchos otros ni aparecen ya que para mi criterio no cobraban tanto protagonismo e interes.  

> <span style="color:skyblue;">**Azul clarito**</span> = Nombre del Módulo  
<span style="color:blue;">**Azul marino**</span> = Nombre de los Submódulos  
<span style="color:purple;">**Morado**</span> = Nombre de las tareas  

<br>

# <span style="color:skyblue;"> **INTRODUCCIÓN HACKING WEB**</span>  

## <span style="color:blue;">**DESCUBRIMIENTO DE CONTENIDO**</span>  

### <span style="color:purple;"> ****_ROBOTS.TXT y SITEMAP.XML_****</span>  

1. **robots.txt**
- Es un archivo de texto que se encuentra en el directorio raíz de un sitio web.
- Su función es dar instrucciones a los motores de búsqueda (bots) sobre qué páginas o secciones del sitio pueden o no deben ser rastreadas o indexadas.
- Utiliza reglas como `User-agent` (para especificar el bot) y `Disallow` (para bloquear secciones específicas del sitio).
- No impide que las páginas sean accesibles, simplemente evita que los motores de búsqueda las rastreen e indexen.

2. **sitemap.xml**
- Es un archivo XML que también se encuentra en el directorio raíz de un sitio web.
- Su función es listar todas las páginas importantes del sitio y proporcionar información adicional como:
  - Fecha de última modificación.
  - Frecuencia de actualización.
  - Prioridad de las páginas.
- Ayuda a los motores de búsqueda a rastrear e indexar el contenido más eficientemente, asegurando que ninguna página importante se quede fuera.  

> Ambas rutas son accesibles publicamente en la mayoria de sitios web

3. **Uso en pentesting de robots.txt**
- _Identificar áreas sensibles_: Al revisar el archivo robots.txt, los pentesters pueden descubrir qué partes del sitio están ocultas para los motores de búsqueda, lo que puede indicar áreas sensibles o confidenciales. Ejemplos comunes pueden incluir rutas como /admin/, /private/ o /backup/, que podrían contener información crítica.

- _Acceso directo_: Aunque robots.txt bloquea el rastreo, no bloquea el acceso directo. Un pentester podría intentar acceder manualmente a las URLs bloqueadas en busca de vulnerabilidades.

4. **Uso en pentesting de sitemap.xml**
- _Mapeo completo del sitio_: Un pentester puede usar el archivo sitemap.xml con aquellas URLs que podrían no estar bien enlazadas desde otras partes del sitio.

- _Prioridades del contenido_: Al ver qué páginas tienen alta prioridad y cuáles se actualizan frecuentemente, un pentester puede identificar áreas donde los desarrolladores están poniendo más esfuerzo o que son más críticas para el negocio, y enfocar sus pruebas allí.  

### <span style="color:purple;"> ****_FAVICON_****</span>  

El favicon es un pequeño ícono que se muestra en la pestaña del navegador y se utiliza para dar estilo y diferenciar un sitio web. Es un archivo `.ico` configurado en el **_head_** del HTML.  

Aunque a primera vista parezca inutil en cuanto al ámbito de pentesting, no es así. A veces cuando un framework es usado para el desarrolo de un sito web, si el desarrolador se olvida de remplazarlo, se quedará el favicon por defecto de dicho framework, lo cual nos daría información de este.  

> Un framework es una estructura o conjunto de herramientas y librerías predefinidas que facilita el desarrollo de aplicaciones al proporcionar soluciones reutilizables para tareas comunes.  

Haciendo un `Ctrl + u` examinamos el código de la págima web donde estamos, arriba en el **_head_** encontraremos una línea donde veremos algo así como `<link rel="shortcut icon" type=images/favicon.ico/>`, claro está que en cada página el nombre del archivo y su ruta será diferente, pero con saber la ruta nos sirve.  

Lo que vamos a hacer a continuacioón es usar la herramienta `curl` (Client URL) para descargarnos el archivo .ico, más tarde explicaré la razón de esto. En la consola de kali ejecutamos `curl https://ejemplo.com/favicon.ico | md5sum`  

Lo que hemos hecho ha sido descargarnos el archivo .ico y obtener su valor **_hash md5_**. El valor hash MD5 es una cadena de caracteres generada a partir de un algoritmo de resumen criptográfico (MD5). 

  - **_curl_** : Este comando utiliza curl para descargar el archivo favicon.ico desde el sitio web ejemplo.com  
  - **|** : Es el simbolo de _pipe_ que toma la salida del comando `curl` y la pasa como entrada al siguiente comando (md5sum)
  - **_md5sum_** : Este comando genera un hash MD5 a partir del contenido del archivo descargado  

Pero...¿Para qué queremos este hash?, el sitio web _OWASP_ (Open Web Application Service Project) cuenta con una base de datos de los hashes _md5_ de muchisimos frameworks, https://wiki.owasp.org/index.php/OWASP_favicon_database. Introduciendo el hash que tengamos en la base dato, podremos encontrar información posiblemente util para nuestros ataques de pentesting.

No es lo más interesante quizás pero desde luego es muy util en casos especificos.  

### <span style="color:purple;">**_ENCABEZADOS HTTP_**</span>  

<span style="color: khaki;">**1. ¿Qué son los encabezados HTTP?**</span>


> Los encabezados HTTP son cadenas de texto que se envían entre el cliente y el servidor para proporcionar información adicional sobre la solicitud o la respuesta. Hay dos tipos principales de encabezados:

- **Encabezados de solicitud (Request headers)**: Son enviados por el cliente al servidor e incluyen información como el agente de usuario, el tipo de contenido aceptado, las cookies, etc.  

- **Encabezados de respuesta (Response headers)**: Son enviados por el servidor al cliente e incluyen detalles como el tipo de contenido devuelto, cookies, políticas de cacheo, información del servidor, etc.  

<span style="color: khaki;">**2. ¿Para qué sirven los encabezados HTTP?**</span>

- **Controlar el comportamiento de la conexión**: Los encabezados permiten ajustar cómo debe manejarse la conexión, como por ejemplo especificar el tipo de contenido que el cliente espera recibir (`Content-Type`) o el tipo de datos aceptados (`Accept`).  

- **Autenticación y gestión de sesiones**: Los encabezados también gestionan la autenticación y las cookies, que son esenciales para mantener sesiones de usuario activas.  

- **Seguridad**: Los encabezados como `Strict-Transport-Security (HSTS)` fuerzan el uso de HTTPS para evitar ataques de intermediarios.  

- **Caching**: Controlan cómo los navegadores deben manejar el contenido en caché (con encabezados como `Cache-Control`, `Expires`).  
 
<span style="color: khaki;">**3. Ejemplo básico**</span>

Para poner un ejemplo de como se ven los encabezados y como son, usaré la herramienta `Curl` anteriormente usada. Es importante enntender que cada página web va a mostrar lineas de codigo de encabezados muy diferentes, mas o menos extensas etc. Siempre es muy util consultar en algun navegador o a alguna IA para entender linea a liena los encabezados.  

`curl https://ejemplo.com -v` es el comando que usaremos con cualquier URL que queramos.  

El comando realiza una solicitud HTTP a la URL especificada, mostrando la conversación completa entre el cliente y el servidor en el proceso.

- **`Curl`**: es una herramienta de línea de comandos que se usa para transferir datos utilizando diferentes protocolos (como HTTP, HTTPS, FTP, etc.).  

- **`https://ejemplo.com`**: Es la URL que vamos a analizar, no tiene porque ser la ruta principal, tambien podriamos poner una ruta más especifica como por ejemplo _`https://ejemplo.com/clientes/premium`_

- **`-v`**: (verbose) es una opción que permite ver información detallada sobre la transacción. Esto incluye todos los encabezados HTTP que se envían y reciben durante la solicitud y respuesta.  

Al ejecutar curl <url> -v, verás algo como esto:  

```
> GET / HTTP/1.1
> Host: example.com
> User-Agent: curl/7.81.0
> Accept: */*

< HTTP/1.1 200 OK
< Date: Thu, 24 Oct 2024 15:00:00 GMT
< Content-Type: text/html; charset=UTF-8
< Server: Apache
< Set-Cookie: sessionID=abcdef; HttpOnly
< Cache-Control: no-cache
```  

Este resultado muestra los encabezados que envía el cliente (`GET`, `Host`, `User-Agent`, `Accept`) y los encabezados que responde el servidor (`Content-Type`, `Server`, `Set-Cookie`, etc.).

 <span style="color: khaki;">**4. ¿Como es esto util en el Pentesting y Hacking Web?**</span>  

 En el contexto de pentesting y hacking web, los encabezados HTTP pueden revelar información crítica sobre la seguridad del sitio web y el comportamiento del servidor. Aquí te explico algunos usos clave:  

- **Identificación del servidor y software**: Encabezados como `Server` o `X-Powered-By` revelan la tecnología que utiliza el servidor (por ejemplo, Apache, Nginx, PHP, etc.). Esta información puede ayudar a identificar posibles vulnerabilidades específicas de esas tecnologías. Ejemplo:  

```
< Server: Apache/2.4.41 (Ubuntu)
< X-Powered-By: PHP/7.4.3
```  

- **Cookies y gestión de sesiones**: Los encabezados como `Set-Cookie` pueden revelar información sobre cómo el servidor gestiona las sesiones. Un mal manejo de cookies puede abrir la puerta a ataques como Session Hijacking o Cross-Site Scripting (XSS) si las cookies no están correctamente protegidas con las banderas `HttpOnly` o `Secure`. Ejemplo:  

```
< Set-Cookie: sessionID=abcdef; HttpOnly
```

- **Políticas de seguridad**: Los encabezados de seguridad como `Content-Security-Policy` (CSP), `X-Frame-Options` o `Strict-Transport-Security` indican si el sitio web está protegido contra ataques como Clickjacking, XSS o ataques de intermediario (MiTM). Ejemplo:  

```
< Strict-Transport-Security: max-age=63072000; includeSubDomains; preload
```

- **Cache-Control y Expires**: Si los encabezados de caché no están configurados correctamente, podrías encontrar problemas de exposición de datos sensibles o posibilidad de atacar mediante técnicas de cache poisoning. Ejemplo:  

```
< Cache-Control: no-cache
```

- **Redirecciones y el encabezado _Location_**: Puedes detectar redirecciones HTTP automáticas que podrían ser útiles para realizar ataques de phishing o redireccionamiento abierto (open redirect). Ejemplo:  

```
< HTTP/1.1 301 Moved Permanently
< Location: https://new-site.com/
```

- **Comportamiento del navegador**: Puedes manipular o analizar cómo el servidor espera que los navegadores traten ciertas solicitudes o respuestas, abriendo la puerta a vectores de ataque como Cross-Origin Resource Sharing (CORS).


### <span style="color:purple;">**_GOOGLE DORKING_**</span>  

<span style="color: khaki;">**1. ¿Qué es Google Dorking?**</span>  

Google Dorking es una técnica de hacking que utiliza operadores avanzados de búsqueda de Google para encontrar información específica y a veces sensible en sitios web, como archivos privados, bases de datos, o incluso credenciales que deberían estar protegidas. 

Esta práctica se basa en el uso de los "dorks", consultas de búsqueda específicas que permiten a un atacante descubrir vulnerabilidades o datos expuestos sin necesidad de hackear directamente un sistema.  

<span style="color: khaki;">**2. Ejemplos de Google Dorks y su Explicación**</span> 

**Encontrar archivos de un tipo específico:**

- _Dork:_  `site:ejemplo.com filetype:pdf` 

- Explicación: Este comando buscará todos los archivos PDF relacionados o con el nombre del dominio web que hayamos escrito. Esta técnica podría revelar documentos sensibles que deberían estar protegidos, pero que han sido indexados accidentalmente por Google.

- Posdata: Este comando se puede conmbinar con una palabra entre comillas despues del tipo de archivo; `site:ejemplo filetype:pdf "confidencial"`, esto hará una busqueda de PDFs con el nombre o la palabra "confidencial" relacionados al dominio web "ejemplo.com"  

**Encontrar chats y logs:**

- _Dork:_  `"index of" / "chat/logs"` 

- Explicación: Este comando buscará en el sitio web especificado directorios abiertos que contengan logs de chat. Los directorios llamados "chat/logs" podrían almacenar registros de conversaciones o información relacionada con sesiones de chat que, si no están adecuadamente protegidos, pueden ser accesibles. Estos archivos de log podrían incluir datos sensibles de usuarios, conversaciones privadas o información de soporte, lo cual puede ser un riesgo de privacidad y seguridad.

- Posdata: Este dork se puede modificar para buscar otros tipos de directorios específicos en un dominio en particular, ajustando las palabras clave en la búsqueda (por ejemplo, site:ejemplo.com "index of" / "private/logs"). Esto puede revelar archivos de registro adicionales o carpetas mal configuradas.


**Encontrar cámaras de vigilancia accesibles:**

- _Dork:_ `inurl:"/view.shtml"`

- Explicación: Este comando busca URL que contienen el término /view.shtml, que comúnmente se asocia con páginas de visualización de cámaras de vigilancia. Muchas cámaras IP y sistemas de seguridad utilizan esta estructura de URL para permitir el acceso remoto a la transmisión en vivo o a las configuraciones de la cámara. Usar este dork puede exponer cámaras que no cuentan con contraseñas o configuraciones de seguridad adecuadas, haciéndolas accesibles públicamente.
 
**Listar bases de datos accesibles**

- _Dork:_ `intext:"phpMyAdmin" "Welcome to phpMyAdmin"`  

- Explicación: Este dork busca paneles de administración de phpMyAdmin expuestos, una herramienta común para gestionar bases de datos MySQL. Si no están asegurados adecuadamente, estos paneles pueden permitir acceso directo a bases de datos sensibles.  

**Buscar páginas de error reveladoras**

- Dork: `intext:"Warning: mysql_fetch_array()"`  

- Explicación: Este comando busca mensajes de error relacionados con bases de datos MySQL. Estas páginas de error pueden revelar información técnica útil para un atacante, como la estructura de la base de datos, nombres de tablas o campos, que luego pueden ser explotados.

### <span style="color:purple;">**_WAPPALYZER_**</span>  

**Wappalyzer** es una herramienta que permite identificar las tecnologías y frameworks que utiliza un sitio web. Su propósito es revelar información detallada sobre el software que ejecuta un sitio, como sistemas de gestión de contenido (CMS), lenguajes de programación, bibliotecas JavaScript, servidores web, servicios de análisis, entre otros.  

Esta herramienta es útil para desarrolladores, analistas de seguridad y pentesters porque permite comprender la infraestructura tecnológica de una página web, lo cual es valioso para realizar auditorías, verificar compatibilidades, o detectar posibles vulnerabilidades.

<span style="color: khaki;">**¿Cómo funciona Wappalyzer?**</span>

Wappalyzer inspecciona los encabezados HTTP, los scripts y el código fuente de un sitio web para identificar patrones específicos asociados a ciertas tecnologías. La herramienta utiliza una base de datos con información sobre tecnologías populares y sus características de implementación. A partir de estos patrones, Wappalyzer identifica las tecnologías y presenta un informe detallado.

Wappalyzer está disponible como:

1. **Extensión de navegador** (para Chrome, Firefox, y Edge).
2. **Línea de comandos (CLI)**.
3. **API** para automatizar el análisis a escala.

<span style="color: khaki;">**Ejemplos de Uso de Wappalyzer**</span>

1. **Extensión de Navegador**

Cuando instalas la extensión en tu navegador, puedes visitar cualquier sitio web, y la extensión automáticamente analizará la página y mostrará un resumen de las tecnologías detectadas. Por ejemplo:

- **Sitio:** https://ejemplo.com
- **Resumen de tecnologías:** WordPress (CMS), Google Analytics (Análisis), Nginx (Servidor web), PHP (Lenguaje de programación), MySQL (Base de datos).

2. **Comando CLI para Automatización**

Usar Wappalyzer en la terminal permite realizar un análisis masivo de varios sitios a la vez. Ejemplo de comando en CLI:

```wappalyzer https://ejemplo.com```


3. **API de Wappalyzer**  

La API permite integrarlo en scripts para verificar las tecnologías usadas en varios sitios automáticamente. Esta opción es útil para realizar auditorías de seguridad o para proyectos de investigación.  

### <span style="color:purple;">**DESCUBRIENTOS AUTOMATIZADOS: _FFUF, DIR, GOSBUSTER_**</span>  

<span style="color: khaki;">**¿Qué es el descubrimiento automatizado?**</span>

El descubrimiento automático es el proceso de utilizar herramientas para descubrir contenido en lugar de hacerlo manualmente. Este proceso está automatizado, ya que normalmente contiene cientos, miles o incluso millones de solicitudes a un servidor web. Estas solicitudes comprueban si existe un archivo o directorio en un sitio web, lo que nos da acceso a recursos que antes no sabíamos que existían. Este proceso es posible gracias al uso de un recurso llamado _WORDLISTS_.

<span style="color: khaki;">**¿Qué son las _Wordlists_?**</span>

Las _wordlists_ son simplemente archivos de texto que contienen una larga lista de palabras de uso común; pueden cubrir muchos casos de uso diferentes. Por ejemplo, una lista de palabras de contraseñas incluiría las contraseñas más utilizadas, mientras que en nuestro caso estamos buscando contenido, por lo que necesitaríamos una lista que contenga los nombres de directorios y archivos más utilizados. Un excelente recurso que recomiendo instalar es https://github.com/danielmiessler/SecLists, incluye wordlists de todo tipo.

<span style="color: khaki;">**FFUF**</span>

Ffuf (Fuzz Faster U Fool) es una herramienta de fuerza bruta rápida para fuzzing de contenido web, como directorios, archivos y parámetros. Su velocidad y flexibilidad la hacen ideal para encontrar rutas ocultas, archivos, subdominios y recursos web.

### **Buscar directorios y archivos ocultos en un sitio web:**  

`ffuf -u https://ejemplo.com/FUZZ -w /ruta/a/diccionario.txt`  

- **-u:** Especifica la URL, donde "FUZZ" es el lugar que ffuf probará con cada palabra del diccionario.  

- **-w:** Define el diccionario con palabras para fuzzing.

### **Buscar parámetros GET vulnerables o no documentados:**  

> Los parámetros GET son datos que se envían en la URL de una solicitud HTTP cuando un usuario accede a una página web o realiza una búsqueda.

`ffuf -u https://ejemplo.com/page.php?FUZZ=valor -w /ruta/a/diccionario.txt`

Ffuf tomará cada palabra de la wordlists y la insertará en la posición de FUZZ en la URL. Por ejemplo, si el diccionario contiene palabras como id, token, y session, ffuf generará solicitudes a:

- https://ejemplo.com/page.php?id=valor
- https://ejemplo.com/page.php?token=valor
- https://ejemplo.com/page.php?session=valor

### **Detectar subdominios ocultos de un sitio web:**

`ffuf -u https://FUZZ.ejemplo.com -w /ruta/a/diccionario_subdominios.txt -H "Host: FUZZ.ejemplo.com"`

- **-u:** Especifica la URL, donde "FUZZ" es el lugar que ffuf probará con cada palabra del diccionario.  

- **-w:** Define el diccionario con palabras para fuzzing.  

- **-H:** agrega un encabezado HTTP personalizado a la solicitud.  
 
- **"Host: FUZZ.ejemplo.com"** indica al servidor que la solicitud va dirigida a FUZZ.ejemplo.com. Esto es importante en caso de que el servidor requiera un encabezado Host específico para redirigir correctamente la solicitud al subdominio probado.  

> El encabezado Host asegura que el servidor entienda el subdominio que estás intentando explorar. Esto es vital en la búsqueda de subdominios  

<span style="color: khaki;">**DIRB**</span>

Dirb no se especializa en descubrir subdominios ni parámetros GET. Su función principal es escanear directorios y archivos en rutas específicas de un dominio que se haya proporcionado, utilizando un diccionario de palabras para buscar rutas o archivos potenciales en el sitio web.  

### **Buscar directorios y archivos ocultos en un sitio web:**  

`dirb https://ejemplo.com /ruta/a/diccionario.txt`  

Este es el comando más sencillo pero muy util, ademas, hay otros argumentos adicionales para hacer el escaneo mas eficaz o exacto:  

- **`-r`**: Evitar que se sigan redirecciones. Útil si quieres ver qué redirecciones se encuentran sin ser llevado automáticamente a la nueva URL.  

- **`-x .php`**: Escanear solo archivos de un tipo específico. Si buscas archivos específicos como .php, .html, .txt, puedes especificarlo para reducir el tiempo de búsqueda.  

- **`-f`**: Forzar mostrar códigos HTTP 403/401 (acceso prohibido/no autorizado). Los códigos 403/401 normalmente son ignorados en un escaneo básico, pero forzar su inclusión puede ser útil para detectar rutas restringidas.

- **`-S`**: No mostrar respuestas con código 404 (No encontrado). Para obtener solo rutas que existen, ignorando las que devuelvan error 404.

- **`-p`**: Especificar un proxy. Útil si estás usando un proxy para monitorear el tráfico, como Burp Suite.VV

<span style="color: khaki;">**GOBUSTER**</span>

Gobuster es una herramienta de fuerza bruta diseñada para descubrir directorios y archivos ocultos en un servidor web, así como subdominios, mediante la ejecución de ataques basados en diccionarios.  

Utiliza la velocidad de `Go` para ejecutar solicitudes rápidamente, lo que lo hace útil en auditorías de seguridad para identificar rutas y recursos no documentados en sitios web.  

> La "velocidad de Go" se refiere a Go (o Golang), el lenguaje de programación en el que está escrito gobuster. Go es un lenguaje desarrollado por Google que es conocido por ser muy eficiente y rápido. La concurrencia en Go permite que gobuster envíe muchas solicitudes simultáneamente sin ralentizarse

### **Escaneo de directorios y archivos ocultos en una URL:**  

`gobuster dir -u https://ejemplo.com -w /ruta/a/diccionario.txt`

- **`dir`**: Indica que queremos buscar directorios y archivos.  

- **`-u`**: La URL objetivo.  

- **`-w`**: El diccionario que se usará para la búsqueda.  

### **Escaneo de subdominios:**  

`gobuster dns -d ejemplo.com -w /ruta/a/diccionario_subdominios.txt`  

- **`dns`**: Modo para escanear subdominios.  

- **`-d`**: Dominio base para buscar subdominios.

- **`-w`**: Diccionario para la búsqueda de subdominios.

### **Argumentos adicionales para ejecutar _Gobuster_**  

- **`-r`**: Evitar que se sigan redirecciones. Útil si quieres ver qué redirecciones se encuentran sin ser llevado automáticamente a la nueva URL.  

- **`-x .php`**: Escanear solo archivos de un tipo específico. Si buscas archivos específicos como .php, .html, .txt, puedes especificarlo para reducir el tiempo de búsqueda.  

- **`-f`**: Forzar mostrar códigos HTTP 403/401 (acceso prohibido/no autorizado). Los códigos 403/401 normalmente son ignorados en un escaneo básico, pero forzar su inclusión puede ser útil para detectar rutas restringidas.

- **`-S`**: No mostrar respuestas con código 404 (No encontrado). Para obtener solo rutas que existen, ignorando las que devuelvan error 404.

- **`-p`**: Especificar un proxy. Útil si estás usando un proxy para monitorear el tráfico, como Burp Suite.  

- **`-t <n>`**: Especificar el número de hilos. Permite aumentar la velocidad del escaneo al realizar múltiples solicitudes simultáneamente. Por ejemplo, -t 50 enviará 50 solicitudes al mismo tiempo.  

## <span style="color:blue;">**ENUMERACION DE SUBDOMINIOS**</span>  

### <span style="color:purple;">**SSL/TLS Y CERTIFICADOS**</span>  

<span style="color: khaki;">**¿Qué es SSL/TLS?**</span>

SSL/TLS (Secure Sockets Layer / Transport Layer Security) es un protocolo de seguridad que encripta la comunicación entre un cliente (como un navegador) y un servidor web, garantizando que los datos transmitidos sean confidenciales y no se puedan interceptar o manipular.  

SSL fue el protocolo original, pero TLS es su versión mejorada y más segura, reemplazándolo casi por completo en la actualidad. Esta tecnología es fundamental para proteger información sensible, como contraseñas, datos personales y transacciones financieras, y se reconoce fácilmente en los sitios web que utilizan "https://" en sus URL.  

<span style="color: khaki;">**Funciones de SSL/TLS en HTTPS**</span>

- **Cifrado**: SSL/TLS cifra la información que se envía entre el cliente y el servidor, lo que impide que los atacantes puedan leer los datos interceptados.

- **Integridad**: SSL/TLS asegura que los datos no sean alterados durante la transmisión. Si los datos son modificados, el receptor puede detectarlo.

- **Autenticación**: SSL/TLS permite la verificación de la identidad del servidor mediante certificados digitales. Esto asegura que el cliente se está comunicando con el servidor correcto y no con un impostor.

<span style="color: khaki;">**Evolución de SSL a TLS**</span>  

- **SSL**: Originalmente desarrollado por Netscape, ha sido reemplazado por TLS debido a las vulnerabilidades descubiertas en las versiones de SSL. Las versiones de SSL son consideradas inseguras y ya no se deben utilizar.

- **TLS**: Es el sucesor de SSL y se ha vuelto el estándar para la seguridad en la web. TLS ha pasado por varias actualizaciones (TLS 1.0, 1.1, 1.2, y más recientemente, 1.3), mejorando la seguridad y el rendimiento.  

<span style="color: khaki;">**Cifrados fundamentales y cifrados a evitar**</span>  

En SSL/TLS, es fundamental utilizar algoritmos de cifrado fuertes para asegurar la privacidad y autenticidad de los datos transmitidos. Los cifrados recomendados suelen ser los basados en AES (Advanced Encryption Standard) con claves de al menos 128 o 256 bits, y algoritmos de intercambio de claves seguros como ECDHE (Elliptic Curve Diffie-Hellman Ephemeral), que ofrece confidencialidad perfecta hacia adelante, es decir, incluso si la clave de un servidor se compromete en el futuro, las sesiones pasadas no pueden ser descifradas.  

Por otro lado, los cifrados que deben evitarse incluyen RC4 y 3DES (Triple DES), ambos considerados obsoletos y vulnerables. RC4, por ejemplo, es susceptible a ataques estadísticos, lo que significa que un atacante puede analizar patrones en el tráfico cifrado y deducir parte de la información original. 3DES tiene una longitud de clave efectiva limitada y puede ser vulnerable a ataques como el "Sweet32", que explota colisiones en bloques repetidos de texto cifrado en conexiones largas.  

Usar cifrados débiles en SSL/TLS puede tener consecuencias graves. Las conexiones podrían ser vulnerables a una amplia gama de ataques, como:

- **Ataques de intercepción y de Hombre en el Medio (MitM)**: Un atacante podría interceptar y descifrar datos sensibles, como contraseñas, números de tarjetas de crédito y otros datos confidenciales.

- **Compromiso de la privacidad**: Al romper un cifrado débil, un atacante podría leer y manipular información transmitida entre cliente y servidor, sin que el usuario o el servidor lo detecten.

- **Suplantación de identidad**: Los cifrados débiles también pueden permitir a los atacantes hacerse pasar por el servidor legítimo, engañando a los usuarios para que revelen información confidencial en un sitio web falso.  

<span style="color: khaki;">**Certificados Digitales y Autoridades de Certificación**</span>  

En el contexto de SSL/TLS, los certificados digitales y las autoridades de certificación (CAs) son componentes clave para asegurar la autenticidad y seguridad de las comunicaciones en línea. Los certificados digitales son archivos electrónicos que vinculan una clave pública con una entidad (por ejemplo, un dominio web), y su propósito es probar que esa entidad es quien dice ser. Esto es fundamental para evitar ataques de suplantación de identidad, como el phishing.  

Un certificado digital contiene varios elementos que lo hacen único y confiable:

- **Clave Pública**: Esta es la clave que el servidor usará para establecer conexiones cifradas. Cuando el cliente (por ejemplo, un navegador) se conecta al servidor, utiliza esta clave para iniciar un canal seguro de comunicación.
- **Identidad del Propietario**: Contiene información sobre la entidad dueña del certificado, como el nombre de dominio (para certificados web), la organización y la ubicación geográfica.
- **Firma Digital de la CA**: La autoridad de certificación firma el certificado digital, lo cual garantiza que ha verificado la identidad de la entidad a la que se emitió el certificado.
- **Período de Validez**: Los certificados tienen una fecha de expiración. Una vez que expiran, ya no son válidos y deben ser renovados.  

Las autoridades de certificación (CAs) son organizaciones de confianza encargadas de emitir, verificar y revocar certificados digitales. Las CAs actúan como una tercera parte confiable entre el cliente y el servidor, y su función principal es confirmar que la entidad que solicita el certificado es legítima.  

<span style="color: khaki;">**Ataques POODLE y BEAST**</span>  

- ***BEAST***: El ataque BEAST (Browser Exploit Against SSL/TLS) fue presentado en 2011 y se dirige a las implementaciones de TLS 1.0. Este ataque explota la debilidad en la forma en que los navegadores y servidores manejan el cifrado utilizando el modo de encadenamiento de bloques (CBC). Un atacante puede interceptar el tráfico cifrado, enviar paquetes manipulados y, mediante un proceso de inyección, recuperar información sensible, como cookies de sesión, al descifrar datos de manera incremental.  

- ***POODLE***: El ataque POODLE (Padding Oracle On Downgraded Legacy Encryption) fue descubierto en 2014 por investigadores de Google y se centra en la vulnerabilidad del protocolo SSL 3.0. Este ataque permite a un atacante forzar a un navegador o servidor a usar SSL 3.0 en lugar de una versión más segura de TLS, aprovechando el modo de cifrado y la forma en que se manejan los bloques de datos. A través de un ataque de oracle, el atacante puede inyectar datos y, al observar las respuestas del servidor, deducir información sensible, como cookies de sesión.  

Este último, ataque POODLE, es un ataque de downgrade, es un ataque donde se fuerza al servidor/navegador a usar un protocolo o version de cifrado más debil y con ello explotar vulnerabilidades de dichas protocolos o versiones.  

***POODLE*** explota la vulnerabilidad en SSL 3.0. Un atacante puede forzar a un navegador o servidor a utilizar SSL 3.0 en lugar de TLS. Una vez que la conexión se establece en SSL 3.0, el atacante puede realizar un ataque de oracle para extraer información sensible, como cookies.  

### <span style="color:purple;"> **_FUERZA BRUTA CON DNS (_Dnsrecon_)_**</span>  

<span style="color: khaki;">**Exploración y Reconocimiento de DNS en Pentesting**</span>

`Dnsrecon` es una herramienta poderosa en el ámbito del reconocimiento de DNS, utilizada principalmente en pruebas de penetración y auditorías de seguridad. La estructura de los nombres de dominio (DNS) es fundamental para que las aplicaciones y servicios en la web operen correctamente, pero también puede ser una fuente de información valiosa para los atacantes si no se asegura adecuadamente.

<span style="color: khaki;">**¿Qué es DNS y por qué es importante?**</span>

El Sistema de Nombres de Dominio (DNS) es un servicio que convierte nombres de dominio legibles por humanos (como `ejemplo.com`) en direcciones IP, que las máquinas pueden entender. Cada registro DNS es un "mapeo" entre un nombre y una dirección, y puede incluir otros detalles sobre los servicios asociados al dominio, como los servidores de correo (registros MX), servidores de nombres (registros NS), y otros.

Al realizar reconocimiento de DNS, un atacante intenta recopilar información sobre estos registros y otros elementos estructurales del dominio que pueden revelar activos de la organización o puntos débiles. Ahí es donde entra `dnsrecon`, facilitando el descubrimiento de registros y subdominios de forma precisa y rápida.

<span style="color: khaki;">**Usos de `dnsrecon` para un Pentester o Atacante**</span>

Para un pentester, `dnsrecon` sirve para:

1. **Mapear la infraestructura de red**: Al identificar subdominios y registros DNS, un pentester puede construir un esquema de los activos de red y servicios disponibles públicamente en una organización.  

2. **Identificar subdominios expuestos**: Subdominios específicos pueden exponer servicios vulnerables o puntos débiles. Con fuerza bruta, `dnsrecon` puede ayudar a encontrar estos subdominios.  

3. **Detectar errores de configuración**: Algunos registros DNS pueden estar mal configurados y exponer detalles que deberían estar restringidos, como las transferencias de zona DNS.  

4. **Identificar servicios activos**: Al obtener registros SRV y TXT, se pueden descubrir servicios específicos del dominio, como VoIP, LDAP, entre otros.  

<span style="color: khaki;">**Análisis detallado del comando `dnsrecon -t brt -d ejemplo.com`**</span>

El comando `dnsrecon -t brt -d ejemplo.com` es un ejemplo común que permite realizar un ataque de fuerza bruta para descubrir subdominios del dominio `ejemplo.com`. A continuación, se detalla el funcionamiento de cada argumento:

- **`-t brt`**: Este argumento indica el tipo de ataque, en este caso, _brt_ (brute force, o fuerza bruta). _dnsrecon_ usará un diccionario de subdominios (generalmente configurado por defecto o personalizado) para intentar adivinar los subdominios de _ejemplo.com_, como _mail.ejemplo.com_, _vpn.ejemplo.com_, _admin.ejemplo.com_, etc. Este método es útil porque muchos subdominios no están enlazados directamente en el sitio web y pueden contener servicios internos o aplicaciones de administración.  

- **`-d ejemplo.com`**: Especifica el dominio objetivo para el cual _dnsrecon_ intentará realizar la fuerza bruta de subdominios.

Este comando ayuda a descubrir subdominios activos sin depender de una transferencia de zona DNS, que muchas veces está restringida. Encontrar subdominios puede permitir a un atacante centrarse en servicios específicos, aplicaciones de administración, o puntos vulnerables en la red.

<span style="color: khaki;">**Otros Comandos y Argumentos Útiles de _dnsrecon_**</span>

`Dnsrecon` cuenta con diversos tipos de consultas que pueden emplearse en distintas etapas de un pentesting. Algunos comandos adicionales y sus usos son:

1. **Transferencias de zona con `-t axfr`**: La transferencia de zona es un método donde un servidor DNS "transfiere" toda la información de su zona de nombres a otro servidor DNS. Cuando una transferencia de zona está mal configurada y abierta al público, permite a un atacante obtener toda la estructura DNS del dominio, lo que incluye subdominios y direcciones IP internas.
    ```bash
    dnsrecon -t axfr -d ejemplo.com
    ```
    > Este comando intenta realizar una transferencia de zona en cada servidor de nombres (NS) del dominio. Si alguno permite transferencias de zona, expondrá toda la infraestructura de `ejemplo.com`.  

<br>

2. **Consulta de registros SRV con `-t srv`**: Los registros SRV en DNS especifican servicios en un dominio, como LDAP, SIP, o Active Directory. Estos servicios pueden ser críticos y, si están expuestos, pueden ser puntos de ataque.
    ```bash
    dnsrecon -t srv -d ejemplo.com
    ```
    > Al ejecutar este comando, `dnsrecon` intenta localizar servicios asociados al dominio. Esto puede ser útil para identificar configuraciones de red específicas o puntos de acceso de servicios internos.  

<br>

3. **Consulta de registros comunes con `-t std`**: `dnsrecon` permite realizar una consulta estándar (`std`) que recopila información básica como los registros `A`, `AAAA`, `MX`, `NS`, `SOA` y `TXT`. Estos registros suelen estar disponibles públicamente y pueden ser el primer paso en el reconocimiento de un dominio.
    ```bash
    dnsrecon -t std -d ejemplo.com
    ```
    > Este comando puede revelar información importante como servidores de correo (MX) y servidores de nombres (NS), permitiendo al pentester entender mejor la estructura pública de DNS.  

<br>

4. **Uso de un diccionario con `-D <wordlist>`**: `dnsrecon` permite especificar un diccionario personalizado de subdominios con el argumento `-D`. Esto permite probar nombres de subdominios específicos que el atacante cree que podrían existir (por ejemplo, nombres de aplicaciones internas o de departamentos).
    ```bash
    dnsrecon -t brt -d ejemplo.com -D /ruta/diccionario.txt
    ```
    > Es útil cuando se dispone de un diccionario especializado, como listas de nombres de subdominios comunes en entornos empresariales (`admin`, `portal`, `vpn`, etc.).  

<br>

5. **Consulta inversa de DNS con `-r <range>`**: Este comando permite realizar consultas de DNS inversas en un rango de IPs, proporcionando un mapeo de nombres de dominio asociados a direcciones IP en un rango determinado. Esto es útil para descubrir activos en bloques de IP.
    ```bash
    dnsrecon -r 192.168.1.0-192.168.1.255
    ```
    > Con inversa me refiero a pasar de una direccion IP a un nombre de dominio, en vez de al reves  

<br>

6. **Formato de salida con `-z`**: `dnsrecon` permite exportar los resultados en formatos JSON o XML con el argumento `-z`. Esto facilita la integración de los datos en otros procesos o la generación de informes detallados.
    ```bash
    dnsrecon -t brt -d ejemplo.com -z
    ```
    > Al usar `-z`, el pentester puede documentar mejor los resultados y automatizar el análisis con otras herramientas.  

<br>

<span style="color: khaki;">**Ejemplo de uso en un escenario de pentesting**</span>

Supongamos que un pentester realiza pruebas en una organización con el dominio `ejemplo.com`. Primero, usará `dnsrecon -t std -d ejemplo.com` para recopilar registros básicos y obtener información sobre los servidores de nombres y correo. Luego, intentará un ataque de fuerza bruta de subdominios con `dnsrecon -t brt -d ejemplo.com`. Esto puede revelar subdominios como `vpn.ejemplo.com` o `test.ejemplo.com`, que podrían estar menos protegidos.

Por último, el pentester podría intentar `dnsrecon -t axfr -d ejemplo.com` para ver si es posible realizar una transferencia de zona, lo cual, si es exitoso, expondrá toda la estructura de DNS, incluyendo IPs internas y servicios que no están destinados a estar disponibles públicamente.

### <span style="color:purple;"> **_VIRTUAL HOSTS_**</span> 

<span style="color: khaki;">**¿A que se refiere "Virtual hosts"?**</span>  

El nombre "Virtual Hosts" se refiere a una funcionalidad en los servidores web que permite que un solo servidor físico (o con una sola dirección IP) pueda alojar múltiples sitios web o aplicaciones. Esto se hace configurando el servidor para que reconozca qué sitio web mostrar basándose en el Host Header de las solicitudes HTTP.  

Por ejemplo:
 
- `www.example.com` y `blog.example.com` pueden apuntar a la misma IP, pero el servidor identifica qué contenido devolver basándose en el Host Header.  

> El Host Header (encabezado Host) es un componente del protocolo HTTP que el navegador o cliente envía al servidor como parte de la solicitud. Su propósito es indicarle al servidor qué sitio web o dominio específico se está solicitando, especialmente cuando varios sitios comparten la misma dirección IP. Se envía automaticamente cuando el cliente envía una solicitud HTTP (buscar una URL). Cuando decimos "envía" nos referimos a transmitir un paquete de información. Así se vería una solicitud HTTP:  

```
GET / HTTP/1.1
Host: www.example.com
User-Agent: Mozilla/5.0
Accept-Language: en-US
```  

> Este paquete se envía al servidor, que lo interpreta y decide qué respuesta devolver.  

En pentesting, el término "Virtual Hosts" se utiliza también para buscar subdominios ocultos o configuraciones específicas en un servidor que puedan ser útiles para descubrir nuevas superficies de ataque.

<span style="color: khaki;">**Automatización de busqueda de subdominios editando el "Host header"**</span>  

> Vamos a usar `ffuf`, ya que es perfecto debido a que con una wordlist y buen posicionamiento de la palabra "ffuz" podemos conseguir encontrar algunos subdominios que no siempre se alojan en resultados DNS de acceso público, como las versiones de desarrollo de una aplicación web o portales de administración.  

`ffuf -w /usr/share/wordlists/SecLists/Discovery/DNS/namelist.txt -H "Host: FUZZ.ejemplo.com" -u http://IP_MAQUINA | column -t`  

Explicación de los parámetros:  

- **-w**: Especifica el wordlist que contiene posibles nombres de subdominios.  
Ejemplo: /usr/share/wordlists/SecLists/Discovery/DNS/namelist.txt podría tener entradas como admin, dev, test, etc.  

- **-H**: Edita/agrega un encabezado HTTP. Aquí modificamos el Host Header.  
Host: FUZZ.acmeitsupport.thm prueba diferentes valores en el lugar de FUZZ usando las palabras del wordlist.  

- **-u**: Especifica la URL objetivo. En este caso, la IP de la máquina.  
Ejemplo: http://MACHINE_IP.  

- **|** : La barra conocida como "Pipe" sirve para conectar la salida de un comando con la entrada de otro comando.

- **column**: El comando column en sistemas basados en Unix/Linux formatea el texto en columnas. Util para convertir texto delimitado (por espacios, tabulaciones o un delimitador específico) en un formato tabular más legible.

- **-t**: le dice al comando column que cree una tabla alineada, separando automáticamente los campos delimitados por espacios o tabulaciones y ajustándolos en columnas bien formateadas.

El anterior comando devuelve todas las respuestas del servidor, incluidas las que no corresponden a subdominios válidos. Los no válidos suelen ser los que más aparecen en el resultado del comando.  

Para evitar tanto output de errores podemos usar el parámetro `-fs` de ffuf (Filter Size), se utiliza para filtrar resultados según el tamaño de la respuesta del servidor. Hay que observar patrones y determinar de que tamaño son las respuestas no válidas.

Por ejemplo:  

- Si al ejecutar el comando vemos que casi todas las lineas tienen: **[size: 2395]** (el numero puede ser completamente diferente,es solo un ejemplo) entonces será probable que este sea el tamaño que indique un subdominio encontrado **NO** válido para nuestro pentesting.

- No estamos del todo seguros pero creemos que el tamaño que queremos ignorar es 2325 ya que es el más repetido, por ello ejecutamos otra vez el comando pero con el parámetro `-fs` donde el número que pondremos será el del tamaño que queremos ignorar, en este caso ignoraremos el tamaño 2395. Nos quedaría un comando tal que así:  


`ffuf -w /usr/share/wordlists/SecLists/Discovery/DNS/namelist.txt -H "Host: FUZZ.ejemplo.com" -u http://IP_MAQUINA -fs 2395 | column -t`  

Con este comando logramos filtrar por tamaño ignorando todos los directorios encontrados con un peso de 2395 y así mostrar solo los utiles. Podemos probar a filtrar con otros tamaños para ver que encontramos.

> Para distinguir mejor el resultado del comando está bien saberse algunos de los distintos números de estatus HTTP: `200 OK` (directorio existente, aunque no implica que nos sea util), `404 Not Found` (directorio no existente), `403 Forbidden` (directorio existente con acceso restringido)  

## <span style="color:blue;">**SALTO/EVASION DE AUTENTICACIÓN (BYPASS)**</span>  

### <span style="color:purple;"> **_ENUMERACIÓN DE USUARIOS_**</span> 

Una buena práctica a la hora de buscar vulnerabilidades en la autenticación y conseguir hacer un "bypass" es hacer una enumeración de usuarios.

Muchas veces los mensajes de error al intentar crear una cuenta en algúna página web nos ayudan a recoletar información. Por ejemplo, al ingresar un nombre de usuario en el "signup", puede que nos salga un mensaje parecido a "Esta cuenta ya existe", "Este nombre está en uso", "Cuenta/nombre no disponible" etc. De este mensaje podemos sacar la conclusión de que ya conocemos el nombre de una cuenta.  

Usando la herramienta `ffuf` podemos ajustar un comando para que mande solicitudes de "signup" con nombres indicados con una "wordlist" y filtrando por un mensaje de respuesta, por ejemplo "Nombre de usuario ya existe", aquí el comando:  

```bash
ffuf -w /usr/share/wordlists/SecLists/Usernames/Names/names.txt -X POST -d "username=FUZZ&email=x&password=x&cpassword=x" -H "Content-Type: application/x-www-form-urlencoded" -u http://url_de_página_de_signup -mr "username already exists"
```

> Es importante entender que el comando hay que ajustarlo para cada persona, intención y características. Ajustar la ruta de la "wordlist", los datos a enviar, el filtro etc.  

1. **`ffuf`** 

Es la herramienta utilizada para realizar fuzzing (pruebas automatizadas enviando múltiples solicitudes con distintos datos). Se emplea para descubrir directorios, archivos, usuarios, parámetros, etc.
 
2. **`-w /usr/share/wordlists/SecLists/Usernames/Names/names.txt`**  

    - **`-w`**  especifica el diccionario o **wordlist**  que se va a usar para el fuzzing.
 
    - **Ruta** : `/usr/share/wordlists/SecLists/Usernames/Names/names.txt` es una wordlist que contiene posibles nombres de usuario para probar en el proceso de enumeración.
 
3. **`-X POST`**  

    - **`-X`**  permite definir el método HTTP de la solicitud.
 
    - **`POST`**  se usa para enviar datos al servidor (en contraste con GET, que envía datos a través de la URL). Se usa POST porque estás enviando datos en el cuerpo de la solicitud (como "username", "email", "password").

    - `GET` es inapropiado aquí porque las solicitudes de registro suelen implicar el envío de datos sensibles, y "GET" enviaría esos datos en la URL, lo que no es seguro y podría ser rechazado por el servidor.
 
4. **`-d "username=FUZZ&email=x&password=x&cpassword=x"`**  

    - **`-d`**  define los datos (payload) que se enviarán en el cuerpo de la solicitud.
 
    - **`username=FUZZ`** : "FUZZ" es un marcador de posición que ffuf reemplazará con cada elemento de la wordlist.
 
    - Los demás campos ("email", "password", "cpassword") están configurados con valores fijos ("x") para completar los requisitos del formulario. Esta "x" es de relleno, es literal, no una variable o incognita, pongo eso para hacerlo sencillo, pero se podría poner cualquier otra cosa, ej "123", "hola" etc
 
5. **`-H "Content-Type: application/x-www-form-urlencoded"`**  

    - **`-H`**  especifica una cabecera HTTP.
 
    - **`Content-Type: application/x-www-form-urlencoded`**  indica que los datos se enviarán en el formato típico de formularios web (pares clave-valor).  

    - Es el formato estándar para formularios "POST" en aplicaciones web. Si no se especifica esta cabecera, el servidor podría rechazar la solicitud.
 
6. **`-u http://url_de_página_de_signup`**  

    - **`-u`**  define la URL objetivo donde se enviarán las solicitudes.

    - La URL apunta a la página de registro donde se quiere probar si un usuario ya existe.
 
7. **`-mr "username already exists"`**  

    - **`-mr`**  (Match Regex) busca una coincidencia con una cadena o patrón en la respuesta del servidor. SOLO mostrará respuestas que contengan ese mensaje, así que es importante ponerlo bien.
 
    - **`"username already exists"`**  se usa para detectar si el servidor indica que el nombre de usuario ya está registrado.

    - **Recomendación**: como es obvio, depende de cada página web, el mensaje de "Nombre de cuenta existente" varía y como es importante ponerlo bien. Mi recomendación es probar a crear una cuenta con alguna nombre que sea probable que esté en uso, despues observar que mensaje te lanza y con eso y sabes como ajustar el comando.  

<br> 

> Posibles errores y mejoras del comando:   
Muchas páginas web estan diseñadas para que el formato de la caja de "correo electrónico" te obligue a poner un estilo de dirección de correo, mediante "@", ".com", ".es" etc. Cambiando el comando en vez de poner "x" pones algo de prueba, por ejemplo "prueba@gmail.com" o algo parecido, solucionaras el problema.  
Si la página web requiere de un "CAPTCHA" al crear una cuenta, esto hara imposible el fuzzing que estamos realizando.  

### <span style="color:purple;"> **_BRUTE FORCE_**</span> 

Ahora que ya sabemos que usuarios existen gracias al comando anterior, podemos proceder a intentar averiguar las contraseñas de estos con fuerza bruta. Esto lo haremos en `ffuf` con un comando donde indicaremos dos wordlists, una de nombres de usaurios encontrados y otra de contraseñas comunes.

> Para crear la wordlist de nombres de usuarios encontrados, podemos redirigir la salida (stdout) del comando anterior y redirigirla al archivo que indiquemos. Esto lo haremos con el simbolo ">". Un solo ">" sobreescribe el texto del archivo que indiquemos y ">>" añade el output al archivo indicado pero sin sobreescribir texto que ya haya en dicho archivo. Por ejemplo: `ffuf ....... >> wordlist_nombres.txt`, donde los puntos sustituyen el comando entero y así no vuelvo a poner el codigo entero otra vez.  

Aquí el comando para la fuerza bruta:  

```bash
ffuf wordlist_nombres.txt:W1,/usr/share/wordlists/SecLists/Passwords/Common-Credentials/10-million-password-list-top-100.txt:W2 -X POST -d "username=W1&password=W2" -H "Content-Type: application/x-www-form-urlencoded" -u http://url_de_la_pagina_de_login -fc 200
```  

1. **`-w wordlist_nombres.txt:W1,/usr/share/wordlists/SecLists/Passwords/Common-Credentials/10-million-password-list-top-100.txt:W2`** : 

    - **`-w`**  especifica las listas de palabras (wordlists) que "ffuf" utilizará para hacer el fuzzing.
 
    - **`wordlist_nombres.txt:W1`** : `ffuf` usará el archivo "wordlist_nombres.txt" como lista de nombres de usuario y cada valor en esa lista será reemplazado por "W1" en las solicitudes.
 
    - **`/usr/share/wordlists/SecLists/Passwords/Common-Credentials/10-million-password-list-top-100.txt:W2`** : Este es otro archivo de wordlist, en este caso para contraseñas, y cada valor en este archivo será reemplazado por "W2" en las solicitudes.
    Así, "ffuf" realizará una combinación de cada nombre de usuario (de "wordlist_nombres.txt") con cada contraseña (de "10-million-password-list-top-100.txt"), y en cada combinación se sustituirán "W1" por el nombre de usuario actual y "W2" por la contraseña actual.
 
2. **`-X POST`** : 

    - Esta opción especifica que el tipo de solicitud HTTP será "POST". En este caso, el "POST" se utiliza porque generalmente es el método para enviar datos (como nombres de usuario y contraseñas) a un servidor para realizar un inicio de sesión.
 
3. **`-d "username=W1&password=W2"`** : 

    - Aquí se define el cuerpo de la solicitud "POST". Los datos que se envían son el nombre de usuario y la contraseña. "W1" y "W2" serán reemplazados con los valores actuales de las listas de palabras.

Ejemplo de cómo se enviaría una solicitud:

```text
username=admin&password=12345
```
 
4. **`-H "Content-Type: application/x-www-form-urlencoded"`** : 

    - Este encabezado especifica el tipo de contenido que se está enviando en el cuerpo de la solicitud. "application/x-www-form-urlencoded "es el tipo estándar cuando se envían datos de formulario.
 
5. **`-u http://url_de_la_pagina_de_login`** :  

    - El "-u" indica la URL de destino a la que se enviarán las solicitudes "POST".

    - La URL apunta a la página de registro donde se quiere probar si un usuario ya existe.
 
6. **`-fc 200`** : 

    - Esta opción significa que "ffuf" **ignora**  las respuestas con el código de estado HTTP "200". Esto es útil porque, en muchos casos, si se realiza un fuzzing de credenciales, los intentos exitosos de inicio de sesión podrían dar como resultado una respuesta de estado 200, lo que indica que la página se cargó correctamente (aunque no necesariamente significa que el inicio de sesión haya tenido éxito).
 
    - Con esta opción, solo se mostrarán las respuestas de código de estado diferente de "200", lo que podría indicar un intento fallido o una página de error personalizada.  

        Se que parece que no tiene sentido evitar los codigos de exito y el resto no. Si estás haciendo fuzzing para obtener una combinación correcta de usuario y contraseña, un 200 OK podría ser difícil de interpretar, ya que no sabemos si se refiere a un login correcto o simplemente a una solicitud que se ha procesado sin errores. Al ignorar los 200 OK, te aseguras de que solo se muestren los resultados que tienen respuestas más interesantes y te concentras en las respuestas que marcan una diferencia entre las credenciales incorrectas y correctas.  

---

¿Para qué sirven `W1` y `W2`?  

  - **`W1` y `W2`**  son simplemente variables para poder llamarlas más adelante en el comando. No hay un significado especial detrás de estos nombres. Pueden ser reemplazados por cualquier otra palabra o símbolo que desees, siempre que sigas la misma convención de formato que los utilices después en las solicitudes.  

> ¿Puedo sustituir `W1` y `W2` por otros nombres?  
Sí, puedes sustituir "W1" y "W2" por cualquier otro nombre de tu preferencia. Por ejemplo, podrías hacer algo como:


```
ffuf -w wordlist_nombres.txt:USER,/usr/share/wordlists/SecLists/Passwords/Common-Credentials/10-million-password-list-top-100.txt:PASSWORD -X POST -d "username=USER&password=PASSWORD" -H "Content-Type: application/x-www-form-urlencoded" -u http://url_de_la_pagina_de_login -fc 200
```
---

### <span style="color:purple;"> **_MANIPULACIÓN DE COOKIES_**</span>  

El contenido de algunas cookies puede estar en texto plano, y es obvio lo que hacen. Tomemos, por ejemplo, si estas fueran las cookies establecidas después de un inicio de sesión exitoso:


```mathematica
Set-Cookie: logged_in=true; Max-Age=3600; Path=/
Set-Cookie: admin=false; Max-Age=3600; Path=/
```
Observamos una cookie (`logged_in`), que parece controlar si el usuario ha iniciado sesión o no, y otra (`admin`), que controla si el visitante tiene privilegios de administrador. Siguiendo esta lógica, si modificamos el contenido de las cookies y hacemos una petición, podríamos cambiar nuestros privilegios.

---


#### Explicación de los Comandos y Parámetros 
| Comando/Parámetro | Explicación | 
| --- | --- | 
| Set-Cookie | Indica al navegador que debe almacenar una cookie con un nombre y valor específico. | 
| logged_in=true | La cookie llamada logged_in tiene el valor true, lo que indica que el usuario está logueado. | 
| admin=false | La cookie llamada admin tiene el valor false, lo que indica que el usuario no es administrador. | 
| Max-Age=3600 | La cookie expirará después de 3600 segundos (1 hora). | 
| Path=/ | La cookie es válida para toda la ruta del dominio (raíz del sitio web). |   

Por ejemplo:

```mathematica
curl -H "Cookie: logged_in=true; admin=false" http://MACHINE_IP/cookie-test
```  

Nos mostraría la página pero sin permisos de administrador, en cambio...:  

```mathematica
curl -H "Cookie: logged_in=true; admin=true" http://MACHINE_IP/cookie-test
```  

Nos mostraía la página además de darnos permisos de administrador  

---

**IMPORTANTE**  

Si bien el ejemplo mostrado es útil en un entorno controlado o en laboratorios de aprendizaje, en la realidad manipular cookies para obtener privilegios no autorizados es mucho más complicado. Algunas raazones:

| Desafío de Seguridad | Explicación | 
| --- | --- | 
| Cookies Firmadas o Cifradas | Las cookies suelen estar firmadas o cifradas con claves secretas. Sin la clave correcta, cualquier modificación será detectada y rechazada por el servidor. | 
| Validación del Lado del Servidor | Aunque modifiques la cookie, el servidor puede realizar comprobaciones adicionales para verificar los privilegios del usuario antes de otorgar acceso. | 
| Protección con Tokens (JWT) | Muchas aplicaciones usan JWT, que incluyen información firmada y cifrada. Alterar el token sin la clave correcta lo invalida. | 
| Registros y Alertas de Seguridad | Los intentos de manipulación se registran y pueden generar alertas. Esto puede llevar a bloqueos de IP o investigaciones. | 
| Medidas de Seguridad Adicionales | Se aplican otras capas de seguridad, como autenticación multifactor (MFA) y controles de acceso basados en roles (RBAC), dificultando la escalada de privilegios. |  

---  

<br>

<span style="color: khaki;">**Qué es y tipos de _Hashing_**</span>  

A veces, los valores de las cookies pueden parecer una cadena larga de caracteres aleatorios; estos se llaman hashes (resúmenes o valores de resumen), que son una representación irreversible del texto original. Aquí hay algunos ejemplos con los que puedes encontrarte:  

| Cadena Original | Método Hash | Resultado |
|-----------------|-------------|-----------|
| 1               | md5         | c4ca4238a0b923820dcc509a6f75849b |
| 1               | sha-256     | 6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b |
| 1               | sha-512     | 4dff4ea340f0a823f15d3f4f01ab62eae0e5da579ccb851f8db9dfe84c58b2b37b89903a740e1ee172da793a6e79d560e5f7f9bd058a12a280433ed6fa46510a |
| 1               | sha1        | 356a192b7913b04c54574d18c28d46e6395428ab |  

<br>

Como puedes ver en la tabla de arriba, el resultado del hash de la misma cadena de entrada puede diferir significativamente dependiendo del método de hashing utilizado. Aunque el hash es irreversible, el mismo resultado se produce cada vez, lo cual es útil para nosotros, ya que servicios como [crackstation.net](https://crackstation.net/)
 mantienen bases de datos con miles de millones de hashes y sus cadenas originales.  

<span style="color: khaki;">**Qué es y tipos de _Codificación_**</span>  

La **codificación**  es similar al **hashing**  en que genera lo que parece una cadena de texto aleatoria, pero en realidad, la codificación es reversible. Esto nos lleva a la pregunta: ¿cuál es el propósito de la codificación? La **codificación**  nos permite convertir datos binarios en texto legible por humanos, lo que facilita y asegura la transmisión de estos datos a través de medios que solo admiten caracteres ASCII en texto plano.A diferencia del **hashing** , que es un proceso irreversible, la **codificación**  tiene la ventaja de que los datos originales pueden ser recuperados fácilmente. Esto la convierte en una opción ideal para situaciones donde necesitamos representar datos en un formato que sea compatible con sistemas que solo aceptan texto, como en el caso de ciertos protocolos de comunicación, como HTTP, que utilizan cookies para almacenar información del usuario.
#### Tipos comunes de codificación: 
 
- **Base32** : Convierte los datos binarios a los caracteres A-Z y 2-7. Es menos común que Base64, pero se usa en algunos sistemas de autenticación (como las aplicaciones de autenticación de dos factores, TOTP).
 
- **Base64** : Convierte datos binarios en caracteres a-z, A-Z, 0-9, `+`, `/` y el signo de igual (`=`) como relleno. Base64 es ampliamente utilizado en la codificación de datos para su transmisión a través de protocolos como HTTP, en particular en las cookies o en la autenticación de tokens.

#### Ejemplo práctico: 

Supongamos que un servidor web establece una cookie de sesión después de un inicio de sesión exitoso:


```mathematica
Set-Cookie: session=eyJpZCI6MSwiYWRtaW4iOmZhbHNlfQ==; Max-Age=3600; Path=/
```

Esta cadena codificada en Base64, al decodificarla, tiene el siguiente valor:


```json
{"id":1,"admin":false}
```

> Se descodifica (si usas base32, pues pons 32 en vez de 64) por terminal con el comando `echo -n texto_codificado | base64 -d`

Podemos luego volver a codificarla en Base64, pero esta vez cambiando el valor de "admin" a `true`, lo que nos daría acceso como administrador:

```json
{"id":1,"admin":true}
```

> Se codifica (si usas base32, pues pons 32 en vez de 64) por terminal con el comando `echo -n texto_a_codificar | base64`

Y al codificarlo de nuevo en Base64:


```mathematica
Set-Cookie: session=eyJpZCI6MSwiYWRtaW4iOnRydWV9; Max-Age=3600; Path=/
```  

Este proceso de codificación y decodificación es útil en diversos contextos. Sin embargo, es importante destacar que la codificación no es un mecanismo de **seguridad** . Si los datos codificados están expuestos, pueden ser fácilmente decodificados por un atacante. Esto resalta la importancia de combinar la codificación con otros métodos de seguridad, como la encriptación y la autenticación, para proteger la información sensible. La **codificación**  es útil principalmente para **representación**  y **transporte**  de datos, pero no debe considerarse una medida de protección por sí sola.  

## <span style="color:blue;">**IDOR (_Referencia Directa Insegura a Objetos_)**</span>  


📌 **¿Qué es IDOR?** La vulnerabilidad **IDOR**  (**Insecure Direct Object Reference** , o **Referencia Directa Insegura a Objetos** ) es una debilidad que ocurre cuando una aplicación permite a un usuario acceder directamente a un objeto (como registros, archivos o información privada) mediante un identificador, sin verificar si ese usuario tiene permiso para acceder a dicho recurso.
En términos simples, es como si una aplicación no validara adecuadamente los permisos del usuario antes de mostrar o modificar información sensible.


---

🛠️ **¿Cómo funciona?** 
Las aplicaciones web suelen asignar identificadores a los recursos internos, como números de cliente, IDs de pedido, números de factura, etc. Por ejemplo, en una URL como esta:


```
https://ejemplo.com/perfil?user_id=123
```
Si el usuario cambia manualmente el `user_id=123` por `user_id=124` y obtiene información de otro usuario sin autorización, la aplicación es vulnerable a IDOR.**El problema**  reside en que la aplicación no verifica si el usuario que realiza la petición realmente tiene derecho a acceder al recurso solicitado.

---

🕵️ **Dónde se encuentran comúnmente las vulnerabilidades IDOR**  
- **APIs REST** : Las APIs a menudo utilizan identificadores para recursos, lo que puede llevar a IDOR si no se verifica correctamente la autenticación y autorización.
 
- **Sistemas de gestión de usuarios** : Perfiles de usuario, detalles de cuenta y configuración personal.
 
- **Documentos y archivos** : Descargas de archivos donde los nombres de archivo son predecibles (`file=report_123.pdf`).
 
- **Portales administrativos** : Acceso a registros de soporte, tickets o facturas.


---

⚠️ **Impacto de una vulnerabilidad IDOR**  
- **Filtración de información confidencial** : Acceso no autorizado a datos personales o financieros de otros usuarios.
 
- **Modificación de datos sensibles** : Actualizar o eliminar información perteneciente a otros usuarios.
 
- **Escalamiento de privilegios** : En algunos casos, podría llevar a obtener permisos de administrador o de otros roles con mayores privilegios.


---

🔒 **Cómo prevenir vulnerabilidades IDOR**  
1. **Implementar controles de acceso a nivel de servidor** :
  - Siempre verificar que el usuario autenticado tiene permisos para acceder al recurso solicitado.
 
2. **Evitar referencias directas predecibles** :
  - Utilizar identificadores aleatorios o UUIDs en lugar de IDs secuenciales.
 
3. **Validar siempre las peticiones** :
  - Cada solicitud debe ser validada contra la sesión o token del usuario para asegurar que solo acceden a sus propios datos.
 
4. **Utilizar autenticación y autorización robustas** :
  - Aplicar modelos de control de acceso basados en roles (RBAC) o listas de control de acceso (ACL).
 
5. **Auditar y registrar accesos** :
  - Monitorizar el uso de identificadores para detectar comportamientos anómalos o intentos de enumeración.


---

🔧 **Tips para encontrar IDOR en pruebas de seguridad**  
1. **Modificar parámetros en URLs** : 
  - Prueba cambiar identificadores numéricos en rutas como `/profile/123`, `/order/456`, etc.
 
2. **Interceptar y modificar peticiones** : 
  - Utiliza herramientas como **Burp Suite**  o **OWASP ZAP**  para capturar y editar peticiones HTTP.
 
3. **Enumerar recursos** :
  - Si los IDs son secuenciales, intenta acceder a registros cercanos.
 
4. **Probar en APIs** : 
  - Las APIs pueden ser vulnerables si no implementan controles de acceso adecuados en endpoints como `/api/user/1234`.


---

⏳ **¿Se siguen explotando las vulnerabilidades IDOR hoy en día?** ¡Sí! Las vulnerabilidades **IDOR**  siguen siendo muy comunes en aplicaciones modernas. En el **OWASP Top 10 2021** , la categoría **A01:2021 - Broken Access Control**  (Control de Acceso Roto) ocupa el primer lugar, y las vulnerabilidades IDOR son una parte significativa de esta categoría. Muchas filtraciones de datos y brechas de seguridad ocurren debido a fallos de control de acceso como IDOR.

---

✅ **Resumen** La vulnerabilidad **IDOR**  es un fallo de control de acceso que permite a un atacante acceder a recursos sin autorización. Aunque es fácil de entender y detectar, su impacto puede ser grave. La prevención requiere validar siempre los permisos del usuario y evitar identificadores predecibles.
Estar consciente de esta vulnerabilidad y saber cómo identificarla es fundamental para garantizar la seguridad de las aplicaciones web.
